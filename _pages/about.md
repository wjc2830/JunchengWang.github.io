---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# About Me

I am a Ph.D. student at **The Hong Kong Polytechnic University** (QS: 54th, USNews: 58th), advised by **Prof. Emma Shujun Wang**. My thesis is titled *"Clone Your Instance: Towards Omni-Modality Creation of Digital Twins with Real-Time Interactions"*.

My research interests span a spectrum of **world models**, **multi-modality content generation**, **omni-language models**, **diffusion models**, and **reinforcement learning**. I am interested in advancing cooperative multi-modal artificial intelligence generative content (MMAIGC) by addressing key challenges in real-time interactive content generation. Specifically, my research draws on foundational mechanisms and principles from MMAIGC, and operationalizes them into world models capable of exhibiting multi-modality generation.


# üõ† Skills
- Generative Language Model Pre-Training/Fine-tuning/RL Post-Training
- Diffusion (Flow) Model Fine-tuning
- Image/Video/Audio Tokenizer Training
- Distribution Matching Distillation
- 3D Gaussian Splatting


# üî• News
- *2026.01*: Started research internship at **Advanced Micro Devices (AMD)** working on efficient generative models.
- *2026.01*: One paper accepted to **ICLR 2026** (oral presentation).
- *2026.01*: One paper accepted to **EACL 2026** (main conference).
- *2025.07*: One paper accepted to **EMNLP 2025** (oral presentation).
- *2025.02*: One paper accepted to **CVPR 2025**.

# üìù Publications 

**TL;DR:** ICLR-26, EACL-26, EMNLP-25, CVPR-25, IJCV, IEEE TIP.

- **Decentralized Attention Fails Centralized Signals: Rethinking Transformers for Medical Time Series**, Guoqi Yu\*, **Juncheng Wang**, Chen Yang, Jing Qin, Angelica I Aviles-Rivero, and Shujun Wang, **ICLR 2026** (oral presentation). (\* Junior student advisee.)

- **Language Model Based Text-to-Audio Generation: Anti-Causally Aligned Collaborative Residual Transformers**, **Juncheng Wang**, Chao Xu, Cheng Yu, Zhe Hu, Haoyu Xie, Guoqi Yu, Lei Shang, and Shujun Wang, **EMNLP 2025** (oral presentation)

- **Synchronized Video-to-Audio Generation via Mel Quantization-Continuum Decomposition**, **Juncheng Wang**, Chao Xu, Cheng Yu, Lei Shang, Zhe Hu, Shujun Wang, and Liefeng Bo, **CVPR 2025**

- **Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation with Guided Decoding**, **Juncheng Wang**, Zhe Hu, Chao Xu, Siyue Ren, Yuxiang Feng, Yang Liu, Baigui Sun, and Shujun Wang, **EACL 2026** (main conference)

- **Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**, **Juncheng Wang**, Lei Shang, Ziqi Liu, Wang Lu, Xixu Hu, Zhe Hu, Jindong Wang, and Shujun Wang, **IJCV** (IF: 9.3, JCR-Q1)

- **Crowd Localization From Gaussian Mixture Scoped Knowledge and Scoped Teacher**, **Juncheng Wang**, Junyu Gao, Yuan Yuan, and Qi Wang, **IEEE TIP** (IF: 13.7, JCR-Q1)

- **Think Before You Move: Latent Motion Reasoning for Text-to-Motion Generation**, Yijie Qian\*, **Juncheng Wang**, Yuxiang Feng, Chao Xu, Wang Lu, Yang Liu, Baigui Sun, Yiqiang Chen, Yong Liu, and Shujun Wang, *Preprint (under-review at IEEE TPAMI)*. (\* Junior student advisee.)


# üìñ Education
- *2024.01 - 2027.12 (expected)*, **Ph.D. Student**, The Hong Kong Polytechnic University (QS: 54th, USNews: 58th)
  - Thesis: Clone Your Instance: Towards Omni-Modality Creation of Digital Twins with Real-Time Interactions
  - Advisor: Prof. Emma Shujun Wang
- *2018.09 - 2022.06*, **B.Sc. in School of Automation**, Northwestern Polytechnical University (985, 211 projects of China)


# üíª Work Experience
- *2026.01 - Present*, **Research Intern**, Advanced Micro Devices (AMD)
  - Research Direction: Efficient generative models, including diffusion model and discrete language models.
  - Mentor: Dr. Tong Shen
- *2023.09 - 2025.09*, **Research Intern**, Tongyi Lab, Alibaba Group
  - Research Direction: Foundational diffusion models, audio-centric content generation, controllable content generation.
  - Mentors: Dr. Chao Xu, Lei Shang and Prof. Liefeng Bo


# üéñ Honors and Awards
- *2022*, **NWPU Excellent Bachelor Thesis** (Select 2 out of 239)
- *2021*, **Chinese National Scholarship** (Rank 2 out of 239 as a year-3 undergraduate student)
- *2021*, **China Robot Contest** - First Prize (National Level)


# üí¨ Academic Services

**Conference Reviewer:** CVPR-25, ICCV-25, NeurIPS-25, ICLR-26, ACL-ARR Oct. 2025

**Journal Reviewer:** IEEE TPAMI, IJCV, IEEE TIP, IEEE TMM, IEEE TNNLS
